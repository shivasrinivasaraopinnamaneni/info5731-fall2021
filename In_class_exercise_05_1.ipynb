{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_05-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivasrinivasaraopinnamaneni/info5731-fall2021/blob/main/In_class_exercise_05_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTf41gcPDvDA"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 11/11/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqrv6tU4DvDE"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "jR77rmkqDvDH",
        "outputId": "f43b6daa-c31a-4e26-e712-7c48bcd43b24"
      },
      "source": [
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "  \n",
        "dataset = pd.read_csv(\"stsa-train.txt\", sep='delimiter', header=None) \n",
        "#dataset              \n",
        "dataset = pd.DataFrame(dataset) \n",
        "dataset.columns = [\"Text\"] \n",
        "dataset['Reviews'] = dataset['Text'].str.split(' ').str[0]\n",
        "dataset['Text'] = dataset['Text'].str.split(n=1).str[1]\n",
        "dataset"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0     a stirring , funny and finally transporting re...       1\n",
              "1     apparently reassembled from the cutting-room f...       0\n",
              "2     they presume their audience wo n't sit still f...       0\n",
              "3     this is a visually stunning rumination on love...       1\n",
              "4     jonathan parker 's bartleby should have been t...       1\n",
              "...                                                 ...     ...\n",
              "6915  painful , horrifying and oppressively tragic ,...       1\n",
              "6916  take care is nicely performed by a quintet of ...       0\n",
              "6917  the script covers huge , heavy topics in a bla...       0\n",
              "6918  a seriously bad film with seriously warped log...       0\n",
              "6919  a deliciously nonsensical comedy about a city ...       1\n",
              "\n",
              "[6920 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "dTG1r8bGF4qi",
        "outputId": "771f900b-cc0f-447d-eb66-189c69deaf22"
      },
      "source": [
        "dataset_test = pd.read_csv(\"/content/stsa-test.txt\", sep='delimiter', header=None)        \n",
        "dataset_test = pd.DataFrame(dataset_test) \n",
        "dataset_test.columns = [\"Text\"] \n",
        "dataset_test['Reviews'] = dataset_test['Text'].str.split(' ').str[0]\n",
        "#dataset  \n",
        "dataset_test['Text'] = dataset_test['Text'].str.split(n=1).str[1]\n",
        "dataset_test"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0        no movement , no yuks , not much of anything .       0\n",
              "1     a gob of drivel so sickly sweet , even the eag...       0\n",
              "2     gangs of new york is an unapologetic mess , wh...       0\n",
              "3     we never really feel involved with the story ,...       0\n",
              "4               this is one of polanski 's best films .       1\n",
              "...                                                 ...     ...\n",
              "1816  an often-deadly boring , strange reading of a ...       0\n",
              "1817  the problem with concept films is that if the ...       0\n",
              "1818  safe conduct , however ambitious and well-inte...       0\n",
              "1819  a film made with as little wit , interest , an...       0\n",
              "1820  but here 's the real damn : it is n't funny , ...       0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-jv_GZDGamK",
        "outputId": "72bf154a-a194-4e25-880f-6c96356cd1d9"
      },
      "source": [
        "#Cleaning the data, \n",
        "nltk.download('stopwords') \n",
        "  \n",
        "corpus_train = [] \n",
        "corpus_test = []\n",
        "  \n",
        "for i in range(0, 6920): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_train.append(text)\n",
        "\n",
        "for i in range(0, 1821): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset_test['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_test.append(text)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUXY9xVSGcow",
        "outputId": "8aebb8bb-9927-4a69-e39e-c2e342c72cfb"
      },
      "source": [
        "cv = CountVectorizer(max_features = 1500) \n",
        "  \n",
        "X = cv.fit_transform(corpus_train).toarray() \n",
        "y = dataset.iloc[:, 1].values\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1' '0' '0' ... '0' '0' '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKu36XBiG_vt"
      },
      "source": [
        "# splitting the data set into training set and validation set \n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=123)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynvRuhlIHKHh"
      },
      "source": [
        "#1.MultinomialNB\n",
        "\n",
        "# fitting naive bayes to the training set \n",
        "import sklearn.metrics as metrics \n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(X_train, y_train)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7FFQ-o3IXa1",
        "outputId": "85bbaab6-5b21-42e9-9149-c72a52e5976f"
      },
      "source": [
        "#For calculating the cross-validation scores\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(classifier, X_test, y_test, cv=10)\n",
        "#Printing the scores\n",
        "print(\"multinomialNB\",scores.mean())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multinomialNB 0.5296215201751643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyVwllWADvDJ"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "atOfn2IsDvDK",
        "outputId": "92bc084e-01d5-4f6d-9b68-4e730f38e14b"
      },
      "source": [
        "#Write your code here.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")\n",
        "df\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74dfee98-ac41-45ad-966c-feba24ba00b8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-74dfee98-ac41-45ad-966c-feba24ba00b8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Unlocked_Mobile.csv to Amazon_Unlocked_Mobile (1).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14112</th>\n",
              "      <td>Apple iPhone 4S 32GB (Black) Unlocked - Verizon</td>\n",
              "      <td>Apple</td>\n",
              "      <td>199.00</td>\n",
              "      <td>5</td>\n",
              "      <td>My wife transfered her TracFone Flip Phone acc...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14113</th>\n",
              "      <td>Apple iPhone 4S 32GB (Black) Unlocked - Verizon</td>\n",
              "      <td>Apple</td>\n",
              "      <td>199.00</td>\n",
              "      <td>4</td>\n",
              "      <td>The phone works great! However, I had trouble ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14114</th>\n",
              "      <td>Apple iPhone 4S 32GB (Black) Unlocked - Verizon</td>\n",
              "      <td>Apple</td>\n",
              "      <td>199.00</td>\n",
              "      <td>5</td>\n",
              "      <td>Everything worked out great!!</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14115</th>\n",
              "      <td>Apple iPhone 4S 32GB (Black) Unlocked - Verizon</td>\n",
              "      <td>Apple</td>\n",
              "      <td>199.00</td>\n",
              "      <td>1</td>\n",
              "      <td>Have had problems with the phone. I will never...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14116</th>\n",
              "      <td>Apple iPhone 4S 32GB (Black) Unlocked - Verizon</td>\n",
              "      <td>Apple</td>\n",
              "      <td>199.00</td>\n",
              "      <td>4</td>\n",
              "      <td>Phone works as advertised. Will say that the</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14117 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Product Name  ... Review Votes\n",
              "0      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          1.0\n",
              "1      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "2      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "3      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "4      \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...          0.0\n",
              "...                                                  ...  ...          ...\n",
              "14112    Apple iPhone 4S 32GB (Black) Unlocked - Verizon  ...          0.0\n",
              "14113    Apple iPhone 4S 32GB (Black) Unlocked - Verizon  ...          0.0\n",
              "14114    Apple iPhone 4S 32GB (Black) Unlocked - Verizon  ...          0.0\n",
              "14115    Apple iPhone 4S 32GB (Black) Unlocked - Verizon  ...          0.0\n",
              "14116    Apple iPhone 4S 32GB (Black) Unlocked - Verizon  ...          NaN\n",
              "\n",
              "[14117 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z18dW0MFRUsh",
        "outputId": "e1da675e-8b24-4407-914f-52499e929258"
      },
      "source": [
        "#Data Cleaning\n",
        "df = df[df['Reviews'].notnull()].head(5000)\n",
        "#Removing punctuatiions\n",
        "df['punct'] = df['Reviews'].str.replace('[^\\w\\s].#','')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk \n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "#stopwords removal\n",
        "df['stopwords'] =df['punct'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "#Removing numercis\n",
        "df['numerics']=df['stopwords'].str.replace('[0-9]','')\n",
        "#to lowercase\n",
        "df['lowercase'] =df['numerics'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "df['stemming']=df['lowercase'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "#Lemmatizing\n",
        "from textblob import Word\n",
        "df['clean'] = df['stemming'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df['clean']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       i feel lucki found use (phone u & use hard all...\n",
              "1       nice phone, nice grade pantach revue. veri cle...\n",
              "2                                               veri plea\n",
              "3         it work good goe slow sometim good phone i love\n",
              "4       great phone replac lost phone. the thing volum...\n",
              "                              ...                        \n",
              "4995    thi review product may find everywher www worl...\n",
              "4996    the product good structure. i'm still use braz...\n",
              "4997    the iphon fine. it work good condit one major ...\n",
              "4998                           screen crack realli quick.\n",
              "4999    will never buy anyth again. i receiv work. nei...\n",
              "Name: clean, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYbFRuosRbBB",
        "outputId": "61380df6-7345-42a4-df64-1fb6af17c32a"
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vector = TfidfVectorizer()\n",
        "tfidf = vector.fit_transform(df['clean'].values)\n",
        "tfidf.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 7567)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsAtLdb-Rgox",
        "outputId": "3a0a9b40-9388-4163-848d-96c1d4990a21"
      },
      "source": [
        "#kmodel\n",
        "from sklearn.cluster import KMeans\n",
        "#Defining the k means model\n",
        "kmodel = KMeans(n_clusters = 5, n_jobs = -1,random_state=99)\n",
        "kmodel.fit(tfidf)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=-1, precompute_distances='auto',\n",
              "       random_state=99, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aIX5I25DR8Yc",
        "outputId": "32c4c47c-15a8-4af8-ced7-5b62f1a7207e"
      },
      "source": [
        "#Create the kmodel labels\n",
        "labels_kmeans = kmodel.labels_\n",
        "#Defining the cluster center\n",
        "cluster_center_kmeans=kmodel.cluster_centers_\n",
        "\n",
        "terms = vector.get_feature_names()\n",
        "terms[1:5]\n",
        "#Dataframe with cluster info\n",
        "df['Label'] = kmodel.labels_\n",
        "df"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     2\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...     0\n",
              "...                                                 ...  ...   ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...     0\n",
              "\n",
              "[5000 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74hP6LXASKP_",
        "outputId": "d74fddc4-ecee-4784-9758-8eb7b2e3c265"
      },
      "source": [
        "#Counting the cluster\n",
        "df.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr4QPnjvSTiH",
        "outputId": "59c04a55-3364-4456-ee1e-3466ec0de0bd"
      },
      "source": [
        "print(\"Top terms per cluster:\")\n",
        "#Defing the centroid\n",
        "centroids = kmodel.cluster_centers_.argsort()[:, ::-1]\n",
        "#Creating the loop for finding the top words\n",
        "for i in range(5):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in centroids[i, :5]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top terms per cluster:\n",
            "Cluster 0: phone\n",
            " it\n",
            " work\n",
            " the\n",
            " good\n",
            "Cluster 1: great\n",
            " work\n",
            " phone\n",
            " product\n",
            " price\n",
            "Cluster 2: good\n",
            " veri\n",
            " phone\n",
            " it\n",
            " product\n",
            "Cluster 3: love\n",
            " it\n",
            " phone\n",
            " great\n",
            " daughter\n",
            "Cluster 4: excel\n",
            " product\n",
            " recommend\n",
            " seller\n",
            " phone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud7tBcrtSZVO"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "points = 2 * 100\n",
        "def lower_b(nums, targ): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r: \n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= targ:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZCnMeZlScnC"
      },
      "source": [
        "def com_200th_near_tneigh(x, data): \n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 ) \n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_b(dists, dist)) \n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "    \n",
        "    return dists[199]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhBg6AuHSgcS",
        "outputId": "54469d01-4157-4d4b-b60e-9c7dd8503c91"
      },
      "source": [
        "import numpy as np\n",
        "sent_vectors = []; \n",
        "for sent in df['Reviews']: \n",
        "    sent_vec = np.zeros(100) \n",
        "    cnt_words =0; \n",
        "    for word in sent: \n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "        except:\n",
        "            pass\n",
        "    sent_vec /= cnt_words\n",
        "    sent_vectors.append(sent_vec)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H84OsLgsSk0t",
        "outputId": "be7f20d3-04bd-4241-cda6-2e7e81b30e71"
      },
      "source": [
        "sent_vectors = np.array(sent_vectors)\n",
        "sent_vectors = np.nan_to_num(sent_vectors)\n",
        "sent_vectors.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T8KlHRSOSoN5",
        "outputId": "872d7769-b38f-45e7-a93c-49d75c7f4e68"
      },
      "source": [
        "points = 2 * 100\n",
        "model = DBSCAN(eps = 1, min_samples = points, n_jobs=-1)\n",
        "model.fit(sent_vectors)\n",
        "df['AVG Clus Label'] = model.labels_\n",
        "df\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>Very pleased</td>\n",
              "      <td>very pleased</td>\n",
              "      <td>veri pleas</td>\n",
              "      <td>veri plea</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>It works good but it goes slow sometimes but i...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>It works good goes slow sometimes good phone I...</td>\n",
              "      <td>it works good goes slow sometimes good phone i...</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>it work good goe slow sometim good phone i love</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Great phone to replace my lost phone. The only...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>Great phone replace lost phone. The thing volu...</td>\n",
              "      <td>great phone replace lost phone. the thing volu...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>great phone replac lost phone. the thing volum...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>This review is not for the product as you may ...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>This review product may find everywhere www wo...</td>\n",
              "      <td>this review product may find everywhere www wo...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>thi review product may find everywher www worl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>4</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The product was in good structure. I'm still n...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>The product good structure. I'm still use Braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>the product good structure. i'm still use braz...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>157.0</td>\n",
              "      <td>The iPhone was fine. It works and is in good c...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>The iPhone fine. It works good condition one m...</td>\n",
              "      <td>the iphone fine. it works good condition one m...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>the iphon fine. it work good condit one major ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>2</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>Screen cracked really quick.</td>\n",
              "      <td>screen cracked really quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>screen crack realli quick.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>Apple iPhone 3GS 16GB (Black) - AT&amp;T MC135LL/A</td>\n",
              "      <td>Apple</td>\n",
              "      <td>30.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Will never buy anything again. I received it a...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>Will never buy anything again. I received work...</td>\n",
              "      <td>will never buy anything again. i received work...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>will never buy anyth again. i receiv work. nei...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Product Name  ... AVG Clus Label\n",
              "0     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "2     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "3     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "4     \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "...                                                 ...  ...            ...\n",
              "4995     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4996     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4997     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4998     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "4999     Apple iPhone 3GS 16GB (Black) - AT&T MC135LL/A  ...              0\n",
              "\n",
              "[5000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-K5SMQZSvTT"
      },
      "source": [
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "#Defining the model\n",
        "cluster = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')  \n",
        "Agg=cluster.fit_predict(sent_vectors)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "2iN9h8gNS0xZ",
        "outputId": "abf64f51-def3-4a39-b6a1-502c78263513"
      },
      "source": [
        "# Providing Labels to cluster at each point\n",
        "aggdfa = df\n",
        "aggdfa['AVG Clus Label'] = cluster.labels_\n",
        "aggdfa.head(2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>punct</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>numerics</th>\n",
              "      <th>lowercase</th>\n",
              "      <th>stemming</th>\n",
              "      <th>clean</th>\n",
              "      <th>Label</th>\n",
              "      <th>AVG Clus Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>I feel LUCKY found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucky found used (phone us &amp; used hard ...</td>\n",
              "      <td>i feel lucki found use (phone us &amp; use hard al...</td>\n",
              "      <td>i feel lucki found use (phone u &amp; use hard all...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. Very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. very cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>nice phone, nice grade pantach revue. veri cle...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name  ... AVG Clus Label\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...  ...              0\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvs84cPFTIxv",
        "outputId": "b0beeedf-da62-4c08-bbb3-7d903286b7a1"
      },
      "source": [
        "aggdfa.groupby(['Label'])['clean'].count()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "0    4211\n",
              "1     259\n",
              "2     198\n",
              "3     213\n",
              "4     119\n",
              "Name: clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU22pYrPTN9_",
        "outputId": "2af9b09d-08c5-4525-da66-891925182ed6"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"2 reviews of assigned to cluster \", i)\n",
        "    print(\"-\" * 70)\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][0]]['clean'])\n",
        "    print('\\n')\n",
        "    print(aggdfa.iloc[aggdfa.groupby(['Label']).groups[i][1]]['clean'])\n",
        "    print('\\n')\n",
        "    print(\"_\" * 70)\n",
        "#printing reviews to cluster"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 reviews of assigned to cluster  0\n",
            "----------------------------------------------------------------------\n",
            "i feel lucki found use (phone u & use hard all), phone line someon upgrad sold one. my son like old one final fell apart .+ year want upgrade!! thank seller, realli appreci & honesti re: said use phone.i recommend seller highli & would again!!\n",
            "\n",
            "\n",
            "nice phone, nice grade pantach revue. veri clean set easi set up. never android phone fantast say least. perfect size surf social media. great phone samsung\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  1\n",
            "----------------------------------------------------------------------\n",
            "phone good littl slow phone old great phone temporari right now. thank great deal\n",
            "\n",
            "\n",
            "phone work great. no problem\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  2\n",
            "----------------------------------------------------------------------\n",
            "it work good goe slow sometim good phone i love\n",
            "\n",
            "\n",
            "good condit work good\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  3\n",
            "----------------------------------------------------------------------\n",
            "i like phone i bought mom love\n",
            "\n",
            "\n",
            "i love it!\n",
            "\n",
            "\n",
            "______________________________________________________________________\n",
            "2 reviews of assigned to cluster  4\n",
            "----------------------------------------------------------------------\n",
            "excel product perfect condit\n",
            "\n",
            "\n",
            "excel\n",
            "\n",
            "\n",
            "______________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdgl-SXKDvDK"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "5ZgIQ28nDvDL",
        "outputId": "6bc65660-ecc9-477c-f5ba-4e18c71e19d6"
      },
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "'''The elbow approach is used in K-means clustering to find the optimal number of clusters, although no number of clusters is required in DBSCAN.\n",
        "When compared to the DBSCAN model, K indicates that clustering is easier.\n",
        "When there are a lot of outliers in a dataset, DBSCAN is utilized. Variables such as Minimum points and others are required by DBSCAN.\n",
        "When it comes to the hierarchical model, it generates noise, which is ineffective when dealing with large datasets.\n",
        "K Means clustering can handle large data better than hierarchical clustering. \n",
        "This is due to the linear temporal complexity of K Means. When it comes to hierarchical clustering, the equation is quadratic.'''\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The elbow approach is used in K-means clustering to find the optimal number of clusters, although no number of clusters is required in DBSCAN.\\nWhen compared to the DBSCAN model, K indicates that clustering is easier.\\nWhen there are a lot of outliers in a dataset, DBSCAN is utilized. Variables such as Minimum points and others are required by DBSCAN.\\nWhen it comes to the hierarchical model, it generates noise, which is ineffective when dealing with large datasets.\\nK Means clustering can handle large data better than hierarchical clustering. \\nThis is due to the linear temporal complexity of K Means. When it comes to hierarchical clustering, the equation is quadratic.'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}